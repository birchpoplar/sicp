#+TITLE: SICP Book - Notes & Code
#+AUTHOR: Johnnie Walker
#+PROPERTY: header-args :eval yes
#+PROPERTY: header-args:racket :lang sicp

* Chapter 1 - Building Abstractions with Procedures

** 1.1 Elements of Programming

Simple program to test functionality:

#+begin_src racket :lang sicp
    (inc 45)
#+end_src

#+RESULTS:
: 46

*Combination*: delimited list of expressions within parentheses to denote procedure application.

*Prefix Notation*: useful when a procedure can take an arbitrary number of arguments. Also allows nesting of procedures.

#+BEGIN_SRC racket
  (define pi 3.14159)
  (define radius 10) 

  (* pi (* radius radius))

  (define circumference (* 2 pi radius))

  circumference

#+END_SRC

#+RESULTS:
: 62.8318

Can evaluate primitive expressions. For example evaluating a numeral is the number it names. Then there are special forms, e.g. ~define~, which associates a name with a value.

*** 1.1.4 Compound Procedures
Elements of a powerful programming language (as far as we have learnt about Lisp so far):
1. numbers and arithmetic operations are primitive data and procedures, there is a fundamental ability to represent values and operating on those values
2. Can combine operations via nesting
3. Ability to abstract by associating names with values (and operations)

*Syntactic sugar* refers to language features or constructs that make code easier to read or write, without adding new functionality to the language itself. These constructs are "sugar" because they make the syntax "sweeter" for the programmer, improving clarity and reducing verbosity.

*** 1.1.5 Substitution Model

#+begin_src racket

  (define (square x) (* x x))

  (define (sum-of-squares x y)
    (+ (square x) (square y)))

  (define (f a)
    (sum-of-squares (+ a 1) (* a 2)))

  (f 5)

#+end_src

#+RESULTS:
: 136

Substitution model breaks down when used with "mutable data" and procedures.

Applicative-order execution:
- typical approach for interpreters
- evaluate the body of the procedure with the formal parameters replaced by the corresponding argument
- Often has efficiency over the normal-order method as less repetitive execution (evaluations lead to multiple uses of the resulting value)
- Lisp uses applicative order execution

Normal-order execution:
- replace and substitute until no further substitution can be done, then evaluate
- Can become a lot more complicated when substitution not feasible

Normal-order = fully expand and then reduce.
Applicative-order = evaluate the arguments and then apply.

*** 1.1.6 Conditional Expressions and Predicates

**** Case and If Statements
Sequence of predicates and expressions. The predicates are evaluated until one is found true and then the consequent expression value returned.

Various conditional expression examples:

#+begin_src racket :lang sicp
  (define (abs x)
    (cond ((> x 10) x)
          ((= x 0) 0)
          ((< x 0) (- x))))

  (abs 4)
#+end_src

#+RESULTS:
: #<void>

#+begin_src racket :lang sicp
  (define (abs x)
    (cond ((< x 0) (- x))
          (else x)))
  
  (abs -6)
#+end_src

#+RESULTS:
: 6

~if~ is a special restricted type of conditional that can be used when precisely two cases in the case analysis exist or are needed.

#+begin_src racket :lang sicp
  (define (abs x)
    (if (< x 0)
        (- x)
        x))

  (abs -10)
#+end_src

#+RESULTS:
: 10

Built in ~if~ is a special form. Based on the result of the predicate it only evaluates one of the two branches.

**** Logical Expressions

Tested the exercises in the Racket REPL. See exercises

*** 1.1.7 Example: Square Roots by Newton's Method

*Principle*: In mathematics we are usually concerned with the declarative description, whereas in computer science we are concerned with the imperative description. One defines properties, the other describes how to do things.

*Note*: with AI code generation, feasible for high-level languages to be declerative, and leave the actual how-to or imperative programming to the AI.

#+begin_src racket :lang sicp
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x)
                   x)))

  (define (improve guess x)
    (average guess (/ x guess)))

  (define (average x y)
    (/ (+ x y) 2))

  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))

  (define (sqrt x)
    (sqrt-iter 1.0 x))

  (define (square x)
    (* x x))

    (sqrt (+ 100 37))

#+end_src

#+RESULTS:
: 11.704699917758145

*** 1.1.8 Procedures as Black Box Abstractions

Decomposition is the breaking down of a problem into subproblems.

The crucial aspect is to break down into procedures that accomplish a specifically defined tasks such that they can be used by other procedures. It then abstracts the /how/ and we're concerned only with the /what/.

*Bound variables* are formal parameters for which their use is independent of their name. The bound variable has scope within the procedure that binds it.

If a variable is not bound it is free.

*Therefore, the formal parameters of a procedure are local to that procedure.*

Using a *block structure* it is possible to nest definitions within a procedure. This then avoids proliferation of multiple similar and possibly (probably) conflicting subprocedures across an application.

*Block structure* also allows lexical scoping (or enables lexical scoping) such that commonly referenced or passed variables can be free within the scope of the block strucure, and not visible outwith the structure. The solves for the name-packaging problem, where conflicting names for different variables can (and frequently would) occur.

** 1.2 Procedures & Processes
*** 1.2.1 Linear Recursion and Iteration
*Recursive process*: characterized by a chain of deferred processes, an interpreter must keep track of the processes to be completed later on. If the amount of information needing tracked increases linearly with the function parameter then it is a /linearly recursive process/.

*Iterative process*: this is one where maintaining the state requires knowledge of a series of state variables. Using those variables you can re-create any particular stage or stages of the process. Similarly if the number of iterations grows linearly with the function parameter then it is a /linearly iterative process/.

Iterative processes can be restarted just by knowing the value of the state variables. Recursive processes require the full chain to occur.

A recursive procedure is one that refers to itself. Such a procedure may still result in an iterative process.

*A recursive procedure* is one where the procedure definition refers to the procedure itself, it's a syntactic reference. _A recursive procedure may generate either a recursive or iterative process_.

*Tail Recursion*
Tail recursion is a special kind of recursion where the recursive call is the last operation in the function. This means that once the recursive call is made, there is no further computation needed in the current function frame. Because of this, the current function frame can be discarded, making tail recursion as efficient as a loop in terms of memory usage.

The recursive call is the final operation:
- No additional operations (like additions, multiplications, etc.) are performed after the recursive call.
- This allows the program to "reuse" the current stack frame instead of allocating a new one.


Tail recursion is indeed an efficient form of recursion where the recursive call is the last operation in the function. This allows for optimization by reusing the current stack frame, making it as memory efficient as a loop. For a function to be tail recursive, no computations should occur after the recursive call, ensuring that the stack does not grow with each call.
_Example of tail recursion (from ChatGPT):_

  #+begin_src racket

    (define (factorial n)
      (define (iter acc n)
        (if (= n 0)
            acc
            (iter (* acc n) (- n 1))))
      (iter 1 n))

    (factorial 4)

  #+end_src

  #+RESULTS:
  : 24

*** 1.2.2 Tree Recursion
In general, the number of steps required in a tree-recursive process will be proportional to the number of nodes in a tree. Whereas the space required will be proportional to the maximum depth of the tree. The reason for the latter is that you move through the tree sequentially as the process completes, so the required storage space will fluctuate as you move up and down the branches of the tree.

*Fibonacci*
A linear iterative process, as well as a recursive procedure. Insight here was to use a pair of integers, initialized to ~Fib(1) = 1~ and ~Fib(0) = 0~. And then use the following transformations: 
~a <-- a + b~
~b <-- a~

#+begin_src racket

  (define (fib n)
    (fib-iter 1 0 n))

  (define (fib-iter a b count)
    (if (= count 0)
        b
        (fib-iter (+ a b) a (- count 1))))

  (fib 11)

#+end_src

#+RESULTS:
: 89

*Example: Counting Change*

#+begin_src racket

  (define (count-change amount)
    (cc amount 5))

  (define (cc amount kinds-of-coins)
    (cond ((= amount 0) 1)
          ((or (< amount 0) (= kinds-of-coins 0)) 0)
          (else (+ (cc amount
                       (- kinds-of-coins 1))
                   (cc (- amount
                          (first-denomination kinds-of-coins))
                       kinds-of-coins)))))

  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))

  (count-change 10)

#+end_src

#+RESULTS:
: 4

*ChatGPT* The code defines a procedure =count-change= that calculates the number of ways to make change for a given amount of money using coins of different denominations: 1, 5, 10, 25, and 50 cents. The =cc= function uses a recursive process to consider two scenarios: using the first kind of coin or not using it and continuing with the rest. The result shows that there are 4 ways to make change for 10 cents using these denominations.

#+name: cc-tree
#+header: :results file drawer
#+header: :file cc-tree.png
#+header: :imagemagick yes
#+header: :headers '("\\usepackage{tikz}")
#+begin_src latex

\begin{tikzpicture}
  \node {cc 10 2}
    child {node {cc 10 1\\=1}}
    child {node {cc 5 2}
      child {node {cc 5 1\\=1}}
      child {node {cc 0 2\\=1}}
    };
\end{tikzpicture}
  
#+end_src

#+RESULTS: cc-tree
:results:
[[file:cc-tree.png]]
:end:

*** 1.2.3 Orders of Growth
~R(n)~ is the resource required for an operation of size ~n~. A bit of an abstract or flexible concept, but ~R(n)~ can refer to memory size, number of operations performed, etc.

~R(n)~ has order of growth ~Theta(f(n))~. The order of growth is then expressed as a function of ~n~. So the challenge is to find the appropriate ~f(n)~ for a process, it could be ~n~, ~n^2~, ~log(n)~ and so on.
*** 1.2.4 Exponentiation
Fast exponential procedure grows at ~Theta(log n)~ rate, as opposed to ~Theta(n)~. The difference between this becomes much more significant as ~n~ grows large.

#+BEGIN_QUOTE
Intuition for the Invariant
Imagine that result is like a "bank account" where we’re accumulating the answer, and 
  is the "remaining debt" we need to compute. The invariant ensures that the combined value of result and the "remaining debt" always equals the original total amount 
 . Each step reduces the "debt" (either by squaring or decrementing), while appropriately adjusting the "account balance" (the result).
#+END_QUOTE

#+BEGIN_QUOTE
Why Does This Matter?
The invariant ensures correctness by tying the iterative state to the original problem:
It tells you why the computation works: every step preserves this relationship.
At the end, when b=0, there’s nothing "left to compute," so the result must be a^n.
#+END_QUOTE

#+BEGIN_QUOTE
The iterative process is about finding a more efficient way to calculate a^n.
- The halving/doubling strategy leads to logarithmic growth in the number of steps.
- The invariant ensures that, at every step, the algorithm stays true to the original goal, giving us confidence in its correctness and final result.
#+END_QUOTE

*** 1.2.5 Greatest Common Divisors
Euclid's algorithm:
~GCD(a,b) = GCD(b,r)~
where ~r~ is the remainder from ~a/b~.
*** 1.2.6 Testing for Primalty
(Scanned this section)

** 1.3 Abstractions with Higher-Order Procedures

*** 1.3.1 Procedures as Arguments

#+begin_src racket

  (define (sum-integers a b)
    (if (> a b)
        0
        (+ a (sum-integers (+ a 1) b))))

  (sum-integers 2 3)

#+end_src

#+RESULTS:
: 5
