#+TITLE: SICP Book - Notes & Code
#+AUTHOR: Johnnie Walker
#+PROPERTY: header-args :eval yes
#+PROPERTY: header-args:racket :lang sicp

* Chapter 1 - Building Abstractions with Procedures

** 1.1 Elements of Programming

Simple program to test functionality:

#+begin_src racket :lang sicp
    (inc 45)
#+end_src

#+RESULTS:
: 46

*Combination*: delimited list of expressions within parentheses to denote procedure application.

*Prefix Notation*: useful when a procedure can take an arbitrary number of arguments. Also allows nesting of procedures.

#+BEGIN_SRC racket
  (define pi 3.14159)
  (define radius 10) 

  (* pi (* radius radius))

  (define circumference (* 2 pi radius))

  circumference

#+END_SRC

#+RESULTS:
: 62.8318

Can evaluate primitive expressions. For example evaluating a numeral is the number it names. Then there are special forms, e.g. ~define~, which associates a name with a value.

*** 1.1.4 Compound Procedures
Elements of a powerful programming language (as far as we have learnt about Lisp so far):
1. numbers and arithmetic operations are primitive data and procedures, there is a fundamental ability to represent values and operating on those values
2. Can combine operations via nesting
3. Ability to abstract by associating names with values (and operations)

*Syntactic sugar* refers to language features or constructs that make code easier to read or write, without adding new functionality to the language itself. These constructs are "sugar" because they make the syntax "sweeter" for the programmer, improving clarity and reducing verbosity.

*** 1.1.5 Substitution Model

#+begin_src racket

  (define (square x) (* x x))

  (define (sum-of-squares x y)
    (+ (square x) (square y)))

  (define (f a)
    (sum-of-squares (+ a 1) (* a 2)))

  (f 5)

#+end_src

#+RESULTS:
: 136

Substitution model breaks down when used with "mutable data" and procedures.

Applicative-order execution:
- typical approach for interpreters
- evaluate the body of the procedure with the formal parameters replaced by the corresponding argument
- Often has efficiency over the normal-order method as less repetitive execution (evaluations lead to multiple uses of the resulting value)
- Lisp uses applicative order execution

Normal-order execution:
- replace and substitute until no further substitution can be done, then evaluate
- Can become a lot more complicated when substitution not feasible

Normal-order = fully expand and then reduce.
Applicative-order = evaluate the arguments and then apply.

*** 1.1.6 Conditional Expressions and Predicates

**** Case and If Statements
Sequence of predicates and expressions. The predicates are evaluated until one is found true and then the consequent expression value returned.

Various conditional expression examples:

#+begin_src racket :lang sicp
  (define (abs x)
    (cond ((> x 10) x)
          ((= x 0) 0)
          ((< x 0) (- x))))

  (abs 4)
#+end_src

#+RESULTS:
: #<void>

#+begin_src racket :lang sicp
  (define (abs x)
    (cond ((< x 0) (- x))
          (else x)))
  
  (abs -6)
#+end_src

#+RESULTS:
: 6

~if~ is a special restricted type of conditional that can be used when precisely two cases in the case analysis exist or are needed.

#+begin_src racket :lang sicp
  (define (abs x)
    (if (< x 0)
        (- x)
        x))

  (abs -10)
#+end_src

#+RESULTS:
: 10

Built in ~if~ is a special form. Based on the result of the predicate it only evaluates one of the two branches.

**** Logical Expressions

Tested the exercises in the Racket REPL. See exercises

*** 1.1.7 Example: Square Roots by Newton's Method

*Principle*: In mathematics we are usually concerned with the declarative description, whereas in computer science we are concerned with the imperative description. One defines properties, the other describes how to do things.

*Note*: with AI code generation, feasible for high-level languages to be declerative, and leave the actual how-to or imperative programming to the AI.

#+begin_src racket :lang sicp
  (define (sqrt-iter guess x)
    (if (good-enough? guess x)
        guess
        (sqrt-iter (improve guess x)
                   x)))

  (define (improve guess x)
    (average guess (/ x guess)))

  (define (average x y)
    (/ (+ x y) 2))

  (define (good-enough? guess x)
    (< (abs (- (square guess) x)) 0.001))

  (define (sqrt x)
    (sqrt-iter 1.0 x))

  (define (square x)
    (* x x))

    (sqrt (+ 100 37))

#+end_src

#+RESULTS:
: 11.704699917758145

*** 1.1.8 Procedures as Black Box Abstractions

Decomposition is the breaking down of a problem into subproblems.

The crucial aspect is to break down into procedures that accomplish a specifically defined tasks such that they can be used by other procedures. It then abstracts the /how/ and we're concerned only with the /what/.

*Bound variables* are formal parameters for which their use is independent of their name. The bound variable has scope within the procedure that binds it.

If a variable is not bound it is free.

*Therefore, the formal parameters of a procedure are local to that procedure.*

Using a *block structure* it is possible to nest definitions within a procedure. This then avoids proliferation of multiple similar and possibly (probably) conflicting subprocedures across an application.

*Block structure* also allows lexical scoping (or enables lexical scoping) such that commonly referenced or passed variables can be free within the scope of the block strucure, and not visible outwith the structure. The solves for the name-packaging problem, where conflicting names for different variables can (and frequently would) occur.

** 1.2 Procedures & Processes
*** 1.2.1 Linear Recursion and Iteration
*Recursive process*: characterized by a chain of deferred processes, an interpreter must keep track of the processes to be completed later on. If the amount of information needing tracked increases linearly with the function parameter then it is a /linearly recursive process/.

*Iterative process*: this is one where maintaining the state requires knowledge of a series of state variables. Using those variables you can re-create any particular stage or stages of the process. Similarly if the number of iterations grows linearly with the function parameter then it is a /linearly iterative process/.

Iterative processes can be restarted just by knowing the value of the state variables. Recursive processes require the full chain to occur.

A recursive procedure is one that refers to itself. Such a procedure may still result in an iterative process.

*A recursive procedure* is one where the procedure definition refers to the procedure itself, it's a syntactic reference. _A recursive procedure may generate either a recursive or iterative process_.

*Tail Recursion*
Tail recursion is a special kind of recursion where the recursive call is the last operation in the function. This means that once the recursive call is made, there is no further computation needed in the current function frame. Because of this, the current function frame can be discarded, making tail recursion as efficient as a loop in terms of memory usage.

The recursive call is the final operation:
- No additional operations (like additions, multiplications, etc.) are performed after the recursive call.
- This allows the program to "reuse" the current stack frame instead of allocating a new one.


Tail recursion is indeed an efficient form of recursion where the recursive call is the last operation in the function. This allows for optimization by reusing the current stack frame, making it as memory efficient as a loop. For a function to be tail recursive, no computations should occur after the recursive call, ensuring that the stack does not grow with each call.
_Example of tail recursion (from ChatGPT):_

  #+begin_src racket

    (define (factorial n)
      (define (iter acc n)
        (if (= n 0)
            acc
            (iter (* acc n) (- n 1))))
      (iter 1 n))

    (factorial 4)

  #+end_src

  #+RESULTS:
  : 24

*** 1.2.2 Tree Recursion
In general, the number of steps required in a tree-recursive process will be proportional to the number of nodes in a tree. Whereas the space required will be proportional to the maximum depth of the tree. The reason for the latter is that you move through the tree sequentially as the process completes, so the required storage space will fluctuate as you move up and down the branches of the tree.

*Fibonacci*
A linear iterative process, as well as a recursive procedure. Insight here was to use a pair of integers, initialized to ~Fib(1) = 1~ and ~Fib(0) = 0~. And then use the following transformations: 
~a <-- a + b~
~b <-- a~

#+begin_src racket

  (define (fib n)
    (fib-iter 1 0 n))

  (define (fib-iter a b count)
    (if (= count 0)
        b
        (fib-iter (+ a b) a (- count 1))))

  (fib 11)

#+end_src

#+RESULTS:
: 89

*Example: Counting Change*

#+begin_src racket

  (define (count-change amount)
    (cc amount 5))

  (define (cc amount kinds-of-coins)
    (cond ((= amount 0) 1)
          ((or (< amount 0) (= kinds-of-coins 0)) 0)
          (else (+ (cc amount
                       (- kinds-of-coins 1))
                   (cc (- amount
                          (first-denomination kinds-of-coins))
                       kinds-of-coins)))))

  (define (first-denomination kinds-of-coins)
    (cond ((= kinds-of-coins 1) 1)
          ((= kinds-of-coins 2) 5)
          ((= kinds-of-coins 3) 10)
          ((= kinds-of-coins 4) 25)
          ((= kinds-of-coins 5) 50)))

  (count-change 10)

#+end_src

#+RESULTS:
: 4

*ChatGPT* The code defines a procedure =count-change= that calculates the number of ways to make change for a given amount of money using coins of different denominations: 1, 5, 10, 25, and 50 cents. The =cc= function uses a recursive process to consider two scenarios: using the first kind of coin or not using it and continuing with the rest. The result shows that there are 4 ways to make change for 10 cents using these denominations.

#+name: cc-tree
#+header: :results file drawer
#+header: :file cc-tree.png
#+header: :imagemagick yes
#+header: :headers '("\\usepackage{tikz}")
#+begin_src latex

\begin{tikzpicture}
  \node {cc 10 2}
    child {node {cc 10 1\\=1}}
    child {node {cc 5 2}
      child {node {cc 5 1\\=1}}
      child {node {cc 0 2\\=1}}
    };
\end{tikzpicture}
  
#+end_src

#+RESULTS: cc-tree
:results:
[[file:cc-tree.png]]
:end:

*** 1.2.3 Orders of Growth
~R(n)~ is the resource required for an operation of size ~n~. A bit of an abstract or flexible concept, but ~R(n)~ can refer to memory size, number of operations performed, etc.

~R(n)~ has order of growth ~Theta(f(n))~. The order of growth is then expressed as a function of ~n~. So the challenge is to find the appropriate ~f(n)~ for a process, it could be ~n~, ~n^2~, ~log(n)~ and so on.
*** 1.2.4 Exponentiation
Fast exponential procedure grows at ~Theta(log n)~ rate, as opposed to ~Theta(n)~. The difference between this becomes much more significant as ~n~ grows large.

#+BEGIN_QUOTE
Intuition for the Invariant
Imagine that result is like a "bank account" where we’re accumulating the answer, and 
  is the "remaining debt" we need to compute. The invariant ensures that the combined value of result and the "remaining debt" always equals the original total amount 
 . Each step reduces the "debt" (either by squaring or decrementing), while appropriately adjusting the "account balance" (the result).
#+END_QUOTE

#+BEGIN_QUOTE
Why Does This Matter?
The invariant ensures correctness by tying the iterative state to the original problem:
It tells you why the computation works: every step preserves this relationship.
At the end, when b=0, there’s nothing "left to compute," so the result must be a^n.
#+END_QUOTE

#+BEGIN_QUOTE
The iterative process is about finding a more efficient way to calculate a^n.
- The halving/doubling strategy leads to logarithmic growth in the number of steps.
- The invariant ensures that, at every step, the algorithm stays true to the original goal, giving us confidence in its correctness and final result.
#+END_QUOTE

*** 1.2.5 Greatest Common Divisors
Euclid's algorithm:
~GCD(a,b) = GCD(b,r)~
where ~r~ is the remainder from ~a/b~.
*** 1.2.6 Testing for Primalty
(Scanned this section)

** 1.3 Abstractions with Higher-Order Procedures

Procedures that manipulate procedures are called *higher-order procedures*.

*** 1.3.1 Procedures as Arguments

#+begin_src racket

  (define (sum-integers a b)
    (if (> a b)
        0
        (+ a (sum-integers (+ a 1) b))))

  (sum-integers 2 3)

#+end_src

#+RESULTS:
: 5

Template for /summation/:

\( \sum_{n=a}^b f(n) = f(a) + ... + f(b) \)

Written then in a generic form:

#+begin_src racket

  (define (sum term a next b)
    (if (> a b)
        0
        (+ (term a)
           (sum term (next a) next b))))

  (define (cube x) (* x x x))

  (define (inc n) (+ n 1))

  (define (sum-cubes a b)
    (sum cube a inc b))

  (sum-cubes 1 10)

#+end_src

#+RESULTS:
: 3025

And then here is a great example of why you need an ~identity~ function--when you have another function that takes a procedure as an argument and you want to use just the variable as the result of that procedure.

#+begin_src racket

  (define (sum term a next b)
    (if (> a b)
        0
        (+ (term a)
           (sum term (next a) next b))))

  (define (identity x) x)

  (define (inc n) (+ n 1))

  (define (sum-integers a b)
    (sum identity a inc b))

  (sum-integers 1 10)

#+end_src

#+RESULTS:
: 55

Another example, this time of an integral:

#+begin_src racket

  (define (sum term a next b)
    (if (> a b)
        0
        (+ (term a)
           (sum term (next a) next b))))

  (define (integral f a b dx)
    (define (add-dx x) (+ x dx))
    (* (sum f (+ a (/ dx 2.0))
            add-dx b)
       dx))

  (define (cube x) (* x x x))

  (integral cube 0 1 0.0001)

#+end_src

#+RESULTS:
: 0.24999999874993412

_Remember that the ~term a next b~ are all separate arguments_
The sum function has this signature: (sum term a next b). Here's what each parameter does:
term: A function applied to each value in the summation.
a: The current value in the summation.
next: A function that defines how to compute the next value from the current value.
b: The upper bound of the summation.

So in the integral passing ~add-dx~ is the function to increment the current to the next value, which is ~n dx~ in the formula:

\( \int_{a}^b f = [ f (a + \frac{dx}{2}) + f (a + dx + \frac{dx}{2}) + f (a + 2dx + \frac{dx}{2}) + ...]dx \)

*The trick is in identifying the ~term~ structure*.

*** 1.3.2 Constructing Procedures using ~Lambda~
A resulting ~lambda~ procedure is just a procedure that has not been given a name. Can also use it to create local variables as ~let~.

Example of scoping in a ~let~:

#+begin_src racket

  (define (let_test x)
    (let ((x 3)
          (y (+ x 2)))
      (* x y)))

  (let_test 2)

#+end_src

#+RESULTS:
: 12

Key principle: the ~y~ in the ~let~ takes the outer ~x~ value of 2, not the inner value of 3. The variables in the ~let~ are computer outside of the ~let~.

*** 1.3.3 Procedures as General Methods
Finding roots (zeros) and fixed points (where \( f(x)=x \)) of functions. Here's the fixed point function--note use of recursion in the definition of ~try~:

#+begin_src racket

  (define tolerance 0.00001)

  (define (fixed-point f first-guess)
    (define (close-enough? v1 v2)
      (< (abs (- v1 v2)) tolerance))
    (define (try guess)
      (let ((next (f guess)))
        (if (close-enough? guess next)
            next
            (try next))))
    (try first-guess))

  (fixed-point cos 1.0)

#+end_src

#+RESULTS:
: 0.7390822985224024

*** 1.3.4 Procedures as Returned Values
Can create procedures whose returned values are themselves procedures. Example:

#+begin_src racket

  (define (square x) (* x x))

  (define (average x y) (/ (+ x y) 2))

  (define (average-damp f)
    (lambda (x) (average x (f x))))

  ((average-damp square) 10)

#+end_src

#+RESULTS:
: 55

Reminds me of the hidden passed arguments in Haskell... Pretty much the same approach--you can pass functions and the access to the arguments of that function is implied.

_Summary of section 1.3_

Programming languages impose restrictions on the ways computational elements can be manipulated. Elements with fewest restrictions are said to have /first-class/ status:
1. May be named by variables
2. May be passed as arguments to procedures
3. May be returned as results of procedures
4. May be included in data structures

 Lisp, unlike other common programming languages, awards *procedures full first-class status*.
 
* Chapter 2
** Overview
/Symbolic expressions/ - where the elementary parts can be arbitrary symbols rather than numbers.
** 2.1 Introduction to Data Abstraction
*** 2.1.1 Example: Rational Numbers
Constructor - procedures or methods to create the object from elementary data.
Selector - procedures to select elementary parts from the constructed object.

_Pairs_
Primitive procedure ~cons~ creates a pair from two arguments. ~cons~ stands for /construct/.
~car~ selects the first element, and ~cdr~ the second element. ~car~ means referencing the address, and ~cdr~ means decrement.

[[file:exercises.org::*Exercise 2.1][Exercise 2.1]]

*** 2.1.2 Abstraction Barriers
Procedures at each level are the interfaces that define the abstraction barriers and connect the different levels.

Implementation decisions and design can be left for later in employing data abstraction. As long as you understand the intended output given inputs then you can ignore the actual implementation underneath, considering it effectively a black box.

[[file:exercises.org::*Exercise 2.2][Exercise 2.2]]

Key step in the exercise above is in defining the segment first, making assumptions that something called a point exists. And then you go and implement the point.

*** 2.1.3 What is meant by data?
This actually gets at a thought from the above exercise--there needs to be some additional restrictions around how the defined procedures work. So data is then defined by some collection of constructors and selectors, together with some specified conditions that these procedures must fulfil in order to be a valid representation. In other words, some key rules have to hold true during the execution of those procedures, and that completes the definition of the data in question.

*** 2.1.4 Extended Exercise - Interval Arithmetic

#+begin_src racket

  (define (add-interval x y)
    (make-interval (+ (lower-bound x) (lower-bound y))
                   (+ (upper-bound x) (upper-bound y))))

  (define (mul-interval x y)
    (let ((p1 (+ (lower-bound x) (lower-bound y)))
          (p2 (+ (lower-bound x) (upper-bound y)))
          (p3 (+ (upper-bound x) (lower-bound y)))
          (p4 (+ (upper-bound x) (upper-bound y))))
      (make-interval (min p1 p2 p3 p4)
                     (max p1 p2 p3 p4))))

  (define (div-interval x y)
    (mul-interval x
                  (make-interval (/ 1.0 (upper-bound y))
                                 (/ 1.0 (lower-bound y))))) 

#+end_src

** 2.2 Hierarchical Data and the Closure Property

~cons~ is a construct that has selectors ~car~ and ~cdr~.

The /closure/ property kind of means something is contained enough that it can be nested without any side effects.

*** 2.2.1 Representing Sequences

A ~list~ is a series of nested ~conses~.

#+begin_src racket

  (define (list-ref items n)
    (if (= n 0)
        (car items)
        (list-ref (cdr items) (- n 1))))

  (define listybits (list 51 32 662 262 7274 74 4 774))

  (list-ref listybits 4)

#+end_src

#+RESULTS:
: 7274

Can use ~null?~ to determine the end of the list, and then ~cdr~ to go down the whole list.

#+begin_src racket

  (define (length items)
    (if (null? items)
        0
        (+ 1 (length (cdr items)))))

  (define odds (list 1 3 5 7))

  (length odds)

#+end_src

#+RESULTS:
: 4

That was the recursive style, here's the iterative style:

#+begin_src racket

  (define (length items)
    (define (length-iter a count)
      (if (null? a)
          count
          (length-iter (cdr a) (+ 1 count))))
    (length-iter items 0))

#+end_src

The last line is the initial call to the iterative function with the ~count~ value set to 0.

There's also the ~append~ function:

#+begin_src racket

  (define (append list1 list2)
    (if (null? list1)
        list2
        (cons (car list1) (append (cdr list1) list2))))

  (define x (list 3 4 5 6 1 1 1 1 1 1 1))
  (define y (list 5 6 7 2 56 2 5 23 6 3 2 6 2 63 6))

  (append x y)

#+end_src

#+RESULTS:
: (3 4 5 6 1 1 1 1 1 1 1 5 6 7 2 56 2 5 23 6 3 2 6 2 63 6)

*Mapping over lists*

#+begin_src racket

  (define (map-2 proc items)
    (if (null? items)
        nil
        (cons (proc (car items))
                    (map proc (cdr items)))))

  (map-2 (lambda (x) (* x 100)) (list 1 2 3 4))

#+end_src

#+RESULTS:
: (100 200 300 400)

Map is an important construct as it helps separate the procedures that affect elements of a list from the creation and combination of those lists.


